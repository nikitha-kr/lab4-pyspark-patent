{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 4253 / 5253 - Lab #4 - Patent Problem with Spark DataFrames\n",
    "<div>\n",
    " <h2> CSCI 4283 / 5253 \n",
    "  <IMG SRC=\"https://www.colorado.edu/cs/profiles/express/themes/cuspirit/logo.png\" WIDTH=50 ALIGN=\"right\"/> </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [Spark cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf) is useful as is [this reference on doing joins in Spark dataframe](http://www.learnbymarketing.com/1100/pyspark-joins-by-example/).\n",
    "\n",
    "The [DataBricks company has one of the better reference manuals for PySpark](https://docs.databricks.com/spark/latest/dataframes-datasets/index.html) -- they show you how to perform numerous common data operations such as joins, aggregation operations following `groupBy` and the like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following aggregation functions may be useful -- [these can be used to aggregate results of `groupby` operations](https://docs.databricks.com/spark/latest/dataframes-datasets/introduction-to-dataframes-python.html#example-aggregations-using-agg-and-countdistinct). More documentation is at the [PySpark SQL Functions manual](https://spark.apache.org/docs/2.3.0/api/python/pyspark.sql.html#module-pyspark.sql.functions). Feel free to use other functions from that library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, countDistinct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our session as described in the tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Lab4-Dataframe\") \\\n",
    "    .master(\"local[*]\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the citations and patents data and check that the data makes sense. Note that unlike in the RDD solution, the data is automatically inferred to be Integer() types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = spark.read.load('cite75_99.txt.gz',\n",
    "            format=\"csv\", sep=\",\", header=True,\n",
    "            compression=\"gzip\",\n",
    "            inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "| CITING|  CITED|\n",
      "+-------+-------+\n",
      "|3858241| 956203|\n",
      "|3858241|1324234|\n",
      "|3858241|3398406|\n",
      "|3858241|3557384|\n",
      "|3858241|3634889|\n",
      "+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "citations.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "patents = spark.read.load('apat63_99.txt.gz',\n",
    "            format=\"csv\", sep=\",\", header=True,\n",
    "            compression=\"gzip\",\n",
    "            inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "| PATENT|GYEAR|GDATE|APPYEAR|COUNTRY|POSTATE|ASSIGNEE|ASSCODE|CLAIMS|NCLASS|CAT|SUBCAT|CMADE|CRECEIVE|RATIOCIT|GENERAL|ORIGINAL|FWDAPLAG|BCKGTLAG|SELFCTUB|SELFCTLB|SECDUPBD|SECDLWBD|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|3070801| 1963| 1096|   NULL|     BE|   NULL|    NULL|      1|  NULL|   269|  6|    69| NULL|       1|    NULL|    0.0|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "|3070802| 1963| 1096|   NULL|     US|     TX|    NULL|      1|  NULL|     2|  6|    63| NULL|       0|    NULL|   NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "|3070803| 1963| 1096|   NULL|     US|     IL|    NULL|      1|  NULL|     2|  6|    63| NULL|       9|    NULL| 0.3704|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "|3070804| 1963| 1096|   NULL|     US|     OH|    NULL|      1|  NULL|     2|  6|    63| NULL|       3|    NULL| 0.6667|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "|3070805| 1963| 1096|   NULL|     US|     CA|    NULL|      1|  NULL|     2|  6|    63| NULL|       1|    NULL|    0.0|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "patents.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. imported this to create functions for spark sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Building the “same-state” counts CTE in PySpark\n",
    "\n",
    "- Joining  twice: c (citations) → p_cit (attributes for the citing patent) on CITING = PATENT & c → p_ced (attributes for the cited patent) on CITED = PATENT\n",
    "Using aliases (alias) keeps the two patent joins clear. \n",
    "- Filtering with:U.S. patents only (COUNTRY = 'US'), Both states present/non-empty (isNotNull() and trim(...) != ''). \n",
    "- Same state match between citer and cited (p_cit.POSTATE == p_ced.POSTATE).\n",
    "- Exclude self-citations (CITING != CITED).\n",
    "- Group & aggregate: count rows per CITING to get SAME_STATE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_state_counts = (\n",
    "    citations.alias('c')\n",
    "    .join(patents.alias('p_cit'), F.col('c.CITING') == F.col('p_cit.PATENT'))\n",
    "    .join(patents.alias('p_ced'), F.col('c.CITED') == F.col('p_ced.PATENT'))\n",
    "    .filter(\n",
    "        (F.col('p_cit.COUNTRY') == 'US') &\n",
    "        (F.col('p_ced.COUNTRY') == 'US') &\n",
    "        (F.trim(F.col('p_cit.POSTATE')) != '') & F.col('p_cit.POSTATE').isNotNull() &\n",
    "        (F.trim(F.col('p_ced.POSTATE')) != '') & F.col('p_ced.POSTATE').isNotNull() &\n",
    "        (F.col('p_cit.POSTATE') == F.col('p_ced.POSTATE')) &\n",
    "        (F.col('c.CITING') != F.col('c.CITED'))\n",
    "    )\n",
    "    .groupBy('CITING')\n",
    "    .agg(F.count('*').alias('SAME_STATE'))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Final joining of SAME_STATE COLUMN\n",
    "\n",
    "- Joining counts back to patents and picking the top 10\n",
    "- Joining so each citing patent row carries its SAME_STATE count.\n",
    "- Filter to U.S. patents with a valid state.\n",
    "- Sort by highest SAME_STATE, tie-break by patent id, then limit to 10 rows.\n",
    "- Selecting all patent columns plus the SAME_STATE metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "| PATENT|GYEAR|GDATE|APPYEAR|COUNTRY|POSTATE|ASSIGNEE|ASSCODE|CLAIMS|NCLASS|CAT|SUBCAT|CMADE|CRECEIVE|RATIOCIT|GENERAL|ORIGINAL|FWDAPLAG|BCKGTLAG|SELFCTUB|SELFCTLB|SECDUPBD|SECDLWBD|SAME_STATE|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "|5959466| 1999|14515|   1997|     US|     CA|    5310|      2|  NULL|   326|  4|    46|  159|       0|     1.0|   NULL|  0.6186|    NULL|  4.8868|  0.0455|   0.044|    NULL|    NULL|       125|\n",
      "|5983822| 1999|14564|   1998|     US|     TX|  569900|      2|  NULL|   114|  5|    55|  200|       0|   0.995|   NULL|  0.7201|    NULL|   12.45|     0.0|     0.0|    NULL|    NULL|       103|\n",
      "|6008204| 1999|14606|   1998|     US|     CA|  749584|      2|  NULL|   514|  3|    31|  121|       0|     1.0|   NULL|  0.7415|    NULL|     5.0|  0.0085|  0.0083|    NULL|    NULL|       100|\n",
      "|5952345| 1999|14501|   1997|     US|     CA|  749584|      2|  NULL|   514|  3|    31|  118|       0|     1.0|   NULL|  0.7442|    NULL|  5.1102|     0.0|     0.0|    NULL|    NULL|        98|\n",
      "|5958954| 1999|14515|   1997|     US|     CA|  749584|      2|  NULL|   514|  3|    31|  116|       0|     1.0|   NULL|  0.7397|    NULL|   5.181|     0.0|     0.0|    NULL|    NULL|        96|\n",
      "|5998655| 1999|14585|   1998|     US|     CA|    NULL|      1|  NULL|   560|  1|    14|  114|       0|     1.0|   NULL|  0.7387|    NULL|  5.1667|    NULL|    NULL|    NULL|    NULL|        96|\n",
      "|5936426| 1999|14466|   1997|     US|     CA|    5310|      2|  NULL|   326|  4|    46|  178|       0|     1.0|   NULL|    0.58|    NULL| 11.2303|  0.0765|   0.073|    NULL|    NULL|        94|\n",
      "|5739256| 1998|13983|   1995|     US|     CA|   70060|      2|    15|   528|  1|    15|  453|       0|     1.0|   NULL|  0.8232|    NULL| 15.1104|  0.1124|  0.1082|    NULL|    NULL|        90|\n",
      "|5913855| 1999|14417|   1997|     US|     CA|  733846|      2|  NULL|   606|  3|    32|  242|       0|     1.0|   NULL|  0.7403|    NULL|  8.3595|     0.0|     0.0|    NULL|    NULL|        90|\n",
      "|5925042| 1999|14445|   1997|     US|     CA|  733846|      2|  NULL|   606|  3|    32|  242|       0|     1.0|   NULL|  0.7382|    NULL|  8.3471|     0.0|     0.0|    NULL|    NULL|        90|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_result = (\n",
    "    patents.alias('p')\n",
    "    .join(same_state_counts, F.col('p.PATENT') == F.col('CITING'))\n",
    "    .filter(\n",
    "        (F.col('p.COUNTRY') == 'US') &\n",
    "        (F.trim(F.col('p.POSTATE')) != '') & F.col('p.POSTATE').isNotNull()\n",
    "    )\n",
    "    .orderBy(F.col('SAME_STATE').desc(), F.col('p.PATENT'))\n",
    "    .limit(10)\n",
    "    .select(F.col('p.*'), F.col('SAME_STATE'))\n",
    ")\n",
    "\n",
    "final_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
